[{"path":"https://beckerbenj.github.io/eatFDZ/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Benjamin Becker. Author, maintainer. Sebastian Weirich. Author, contributor. Claudia Neuendorf. Author, contributor.","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Becker B, Weirich S, Neuendorf C (2023). eatFDZ: Forschungsdatenzentrum utility functions. R package version 0.5.0, https://beckerbenj.github.io/eatFDZ/.","code":"@Manual{,   title = {eatFDZ: Forschungsdatenzentrum utility functions},   author = {Benjamin Becker and Sebastian Weirich and Claudia Neuendorf},   year = {2023},   note = {R package version 0.5.0},   url = {https://beckerbenj.github.io/eatFDZ/}, }"},{"path":[]},{"path":"https://beckerbenj.github.io/eatFDZ/index.html","id":"workflow","dir":"","previous_headings":"","what":"Workflow","title":"Forschungsdatenzentrum utility functions","text":"R package automates workflows Forschungsdatenzentrum (FDZ) IQB.","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Forschungsdatenzentrum utility functions","text":"","code":"# Install eatFDZ from GitHub via remotes::install_github(\"beckerbenj/eatFDZ\")  # Install eatAnalysis (for writing Excel files) from GitHub via remotes::install_github(\"beckerbenj/eatAnalysis\")"},{"path":"https://beckerbenj.github.io/eatFDZ/index.html","id":"codebook-checks","dir":"","previous_headings":"","what":"Codebook checks","title":"Forschungsdatenzentrum utility functions","text":"","code":"library(eatFDZ) ### Check if all variables in the data set are mentioned in the codebook out <- check_docu(sav_path = \"example_data.sav\",             pdf_path = \"example_codebook.pdf\", )  # write to Excel eatAnalysis::write_xlsx(out, filePath = \"codebook_checks.xlsx\", row.names = FALSE)"},{"path":"https://beckerbenj.github.io/eatFDZ/index.html","id":"data-cleaning-and-anonymization","dir":"","previous_headings":"","what":"Data cleaning and anonymization","title":"Forschungsdatenzentrum utility functions","text":"","code":"syntax <- data_clean(fileName = sav_path,              saveFolder = tempdir(), nameListe = \"liste2.csv\",              nameSyntax = \"syntax2.txt\", exclude=exclude)"},{"path":"https://beckerbenj.github.io/eatFDZ/reference/check_docu.html","id":null,"dir":"Reference","previous_headings":"","what":"Check documentation of data sets. — check_docu","title":"Check documentation of data sets. — check_docu","text":"Check variables one multiple data sets saved sav included pdf documentation.","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/check_docu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check documentation of data sets. — check_docu","text":"","code":"check_docu(   sav_path,   pdf_path,   post_words = 2,   case_sensitive = FALSE,   encoding = NULL )"},{"path":"https://beckerbenj.github.io/eatFDZ/reference/check_docu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check documentation of data sets. — check_docu","text":"sav_path Character vector paths .sav files. pdf_path Character vector paths .pdf files. post_words Number words variable names extracted PDF. case_sensitive TRUE, upper lower case differentiated variable name matching. FALSE, case ignored. encoding Optional: character encoding used reading .sav file. default, NULL, uses encoding specified file, sometimes value incorrect useful able override .","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/check_docu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check documentation of data sets. — check_docu","text":"data.frame variable names, count mentions pdf (count), words variable names (post) name data set variable occurs (data_set).","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/check_docu.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check documentation of data sets. — check_docu","text":"common requirement data documentation complete codebook. check_docu function can used check, whether variables (column names) one multiple sav data sets mentioned documentation, provided pdf files. Multiple pdf files treated one single pdf file. multiple data sets output sorted data set data_set column indicates data set variable name belongs. Error messages PDF error: Invalid Font Weight can savely ignored. easier reading output, output can written excel file, example using write.xlsx function openxlsx package write_xlsx function eatAnalysis package.","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/check_docu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check documentation of data sets. — check_docu","text":"","code":"# File pathes sav_path1 <- system.file(\"extdata\", \"helper_spss_p1.sav\", package = \"eatFDZ\") sav_path2 <- system.file(\"extdata\", \"helper_spss_p2.sav\", package = \"eatFDZ\") pdf_path1 <- system.file(\"extdata\", \"helper_codebook_p1.pdf\", package = \"eatFDZ\") pdf_path2 <- system.file(\"extdata\", \"helper_codebook_p2.pdf\", package = \"eatFDZ\")  check_df <- check_docu(sav_path = c(sav_path1, sav_path2),                        pdf_path = c(pdf_path1, pdf_path2), post_words = 2)"},{"path":"https://beckerbenj.github.io/eatFDZ/reference/check_docu_excel.html","id":null,"dir":"Reference","previous_headings":"","what":"Check documentation of data sets. — check_docu_excel","title":"Check documentation of data sets. — check_docu_excel","text":"Check variables one multiple data sets saved sav included excel documentation.","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/check_docu_excel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check documentation of data sets. — check_docu_excel","text":"","code":"check_docu_excel(sav_path, excel_path, case_sensitive = FALSE, encoding = NULL)"},{"path":"https://beckerbenj.github.io/eatFDZ/reference/check_docu_excel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check documentation of data sets. — check_docu_excel","text":"sav_path Character vector paths .sav files. excel_path Character vector paths .xlsx files. case_sensitive TRUE, upper lower case differentiated variable name matching. FALSE, case ignored. encoding Optional: character encoding used reading .sav file. default, NULL, uses encoding specified file, sometimes value incorrect useful able override .","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/check_docu_excel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check documentation of data sets. — check_docu_excel","text":"data.frame variable names, count mentions pdf (count), name data set variable occurs (data_set).","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/check_docu_excel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check documentation of data sets. — check_docu_excel","text":"common requirement data documentation complete codebook. check_docu_excel function can used check, whether variables (column names) one multiple sav data sets mentioned documentation, provided excel files. Multiple pdf files treated one single pdf file. multiple data sets output sorted data set data_set column indicates data set variable name belongs. easier reading output, output can written excel file, example using write.xlsx function openxlsx package write_xlsx function eatAnalysis package.","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/check_docu_excel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check documentation of data sets. — check_docu_excel","text":"","code":"# File pathes sav_path1 <- system.file(\"extdata\", \"helper_spss_p1.sav\", package = \"eatFDZ\") sav_path2 <- system.file(\"extdata\", \"helper_spss_p2.sav\", package = \"eatFDZ\") excel_path1 <- system.file(\"extdata\", \"helper_codebook_p1.xlsx\", package = \"eatFDZ\")  check_df <- check_docu_excel(sav_path = c(sav_path1, sav_path2),                        excel_path = c(excel_path1))"},{"path":"https://beckerbenj.github.io/eatFDZ/reference/check_docu_mez.html","id":null,"dir":"Reference","previous_headings":"","what":"Check documentation of data sets. — check_docu_mez","title":"Check documentation of data sets. — check_docu_mez","text":"specific version check_docu written MEZ study. variable name can found documentation, variable name split first numeral * added stem.","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/check_docu_mez.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check documentation of data sets. — check_docu_mez","text":"","code":"check_docu_mez(   sav_path,   pdf_path,   post_words = 2,   case_sensitive = FALSE,   encoding = NULL )"},{"path":"https://beckerbenj.github.io/eatFDZ/reference/check_docu_mez.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check documentation of data sets. — check_docu_mez","text":"sav_path Character vector paths .sav files. pdf_path Character vector paths .pdf files. post_words Number words variable names extracted PDF. case_sensitive TRUE, upper lower case differentiated variable name matching. FALSE, case ignored. encoding Optional: character encoding used reading .sav file. default, NULL, uses encoding specified file, sometimes value incorrect useful able override .","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/check_docu_mez.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check documentation of data sets. — check_docu_mez","text":"data.frame variable names, count mentions pdf (count), words variable names (post) name data set variable occurs (data_set).","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/data_clean.html","id":null,"dir":"Reference","previous_headings":"","what":"Data clean. — data_clean","title":"Data clean. — data_clean","text":"function deprecated, please use sdc_check instead.","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/data_clean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data clean. — data_clean","text":"","code":"data_clean()"},{"path":"https://beckerbenj.github.io/eatFDZ/reference/english_words.html","id":null,"dir":"Reference","previous_headings":"","what":"English Language Corpus — english_words","title":"English Language Corpus — english_words","text":"English language corpus downloaded https://github.com/dwyl/english-words.","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/english_words.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"English Language Corpus — english_words","text":"","code":"english_words"},{"path":"https://beckerbenj.github.io/eatFDZ/reference/english_words.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"English Language Corpus — english_words","text":"character vector 459866 entries.","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/english_words.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"English Language Corpus — english_words","text":"https://github.com/dwyl/english-words english_words","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/german_words.html","id":null,"dir":"Reference","previous_headings":"","what":"German Language Corpus — german_words","title":"German Language Corpus — german_words","text":"German language corpus downloaded https://github.com/davidak/wortliste.","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/german_words.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"German Language Corpus — german_words","text":"","code":"german_words"},{"path":"https://beckerbenj.github.io/eatFDZ/reference/german_words.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"German Language Corpus — german_words","text":"character vector 239649 entries.","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/german_words.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"German Language Corpus — german_words","text":"https://github.com/davidak/wortliste german_words","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/reverse_check_docu.html","id":null,"dir":"Reference","previous_headings":"","what":"Reverse check documentation of data sets. — reverse_check_docu","title":"Reverse check documentation of data sets. — reverse_check_docu","text":"function extracts words pdf file discards words variables data set words white listed. Based list words returned, might listed variables documentation data set.","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/reverse_check_docu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reverse check documentation of data sets. — reverse_check_docu","text":"","code":"reverse_check_docu(   white_list = c(english_words, german_words),   pdf_path,   sav_path,   encoding = NULL )"},{"path":"https://beckerbenj.github.io/eatFDZ/reference/reverse_check_docu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reverse check documentation of data sets. — reverse_check_docu","text":"white_list character vector containing words flagged. Defaults combination German English corpus. pdf_path Character vector paths .pdf files. sav_path Character vector paths .sav files. encoding character encoding used file. default, NULL, use encoding specified file, sometimes value incorrect useful able override .","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/reverse_check_docu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reverse check documentation of data sets. — reverse_check_docu","text":"data.frame columns suspicious_words, missing_documentation comment.","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/reverse_check_docu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reverse check documentation of data sets. — reverse_check_docu","text":"","code":"# File pathes sav_path1 <- system.file(\"extdata\", \"helper_spss_p1.sav\", package = \"eatFDZ\") sav_path2 <- system.file(\"extdata\", \"helper_spss_p2.sav\", package = \"eatFDZ\") pdf_path1 <- system.file(\"extdata\", \"helper_codebook_p1.pdf\", package = \"eatFDZ\") pdf_path2 <- system.file(\"extdata\", \"helper_codebook_p2.pdf\", package = \"eatFDZ\") pdf_path3 <- system.file(\"extdata\", \"helper_codebook_p3.pdf\", package = \"eatFDZ\")  check_df <- reverse_check_docu(sav_path = c(sav_path1, sav_path2),                        pdf_path = c(pdf_path1, pdf_path2, pdf_path3))"},{"path":"https://beckerbenj.github.io/eatFDZ/reference/sdc_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Statistical Disclosure Control Report. — sdc_check","title":"Create a Statistical Disclosure Control Report. — sdc_check","text":"Create statistical disclosure control report: variables categories low absolute frequencies, might lead statistical data disclosure issues?","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/sdc_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Statistical Disclosure Control Report. — sdc_check","text":"","code":"sdc_check(fileName, boundary = 5, exclude = NULL, encoding = NULL)"},{"path":"https://beckerbenj.github.io/eatFDZ/reference/sdc_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Statistical Disclosure Control Report. — sdc_check","text":"fileName Character string SPSS file boundary Integer number: categories less equal boundary observations flagged exclude Optional: character vector variable names excluded report encoding Optional: character encoding used reading .sav file. default, NULL, uses encoding specified file, sometimes value incorrect useful able override .","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/sdc_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Statistical Disclosure Control Report. — sdc_check","text":"data.frame.","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/sdc_check.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Statistical Disclosure Control Report. — sdc_check","text":"Individual participants studies educational large-scale assessments usually must remain non-identifiable individual level. function checks variables GADSdat object low frequency categories might lead statistical disclosure control issues. Currently, uni-variate check implemented.","code":""},{"path":"https://beckerbenj.github.io/eatFDZ/reference/sdc_check.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Statistical Disclosure Control Report. — sdc_check","text":"","code":"sav_path <- system.file(\"extdata\", \"LV_2011_CF.sav\", package = \"eatFDZ\")  ## don't report low frequencies for unique id variables exclude<- c(\"idstud_FDZ\", \"idsch_FDZ\")  ## sdc_report <- sdc_check(fileName = sav_path, exclude=exclude)"}]
